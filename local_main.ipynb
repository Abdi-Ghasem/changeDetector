{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2022 Ghasem Abdi\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "# Original Author       : Ghasem Abdi, ghasem.abdi@yahoo.com\n",
    "# File Last Update Date : April 15, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import os\n",
    "import torch\n",
    "import changeDetector as cd #from src import changeDetector as cd\n",
    "from pytorch_toolbelt import losses as L\n",
    "\n",
    "#define device for running deep learning package\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # chunk train, valid, and test set (optional)\n",
    "# chunker = cd.chunk_data(number_tiles=16)\n",
    "\n",
    "# _ = chunker.chunk(data_root='LEVIR_dataset/train')\n",
    "# _ = chunker.chunk(data_root='LEVIR_dataset/valid')\n",
    "# _ = chunker.chunk(data_root='LEVIR_dataset/test' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare train, valid, and test set\n",
    "train_ds = cd.prepare_data(\n",
    "    data_root='LEVIR_dataset/train',\n",
    "    base_dir='A', \n",
    "    base_img_suffix='*.png',\n",
    "    target_dir='B',\n",
    "    target_img_suffix='*.png',\n",
    "    label_dir='label', \n",
    "    label_mask_suffix='*.png',\n",
    "    size=256,\n",
    "    transform=None\n",
    ")\n",
    "\n",
    "valid_ds = cd.prepare_data(\n",
    "    data_root='LEVIR_dataset/valid',\n",
    "    base_dir='A', \n",
    "    base_img_suffix='*.png',\n",
    "    target_dir='B',\n",
    "    target_img_suffix='*.png',\n",
    "    label_dir='label', \n",
    "    label_mask_suffix='*.png',\n",
    "    size=256,\n",
    "    transform=False\n",
    ")\n",
    "\n",
    "test_ds = cd.prepare_data(\n",
    "    data_root='LEVIR_dataset/test',\n",
    "    base_dir='A',\n",
    "    base_img_suffix='*.png',\n",
    "    target_dir='B',\n",
    "    target_img_suffix='*.png',\n",
    "    label_dir='label',\n",
    "    label_mask_suffix='*.png',\n",
    "    size=256,\n",
    "    transform=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare training and testing data loaders\n",
    "train_dl = {\n",
    "    'train': cd.prepare_dataloader(dataset=train_ds, batch_size=64, shuffle=True, num_workers=os.cpu_count()),\n",
    "    'valid': cd.prepare_dataloader(dataset=valid_ds, batch_size=64, shuffle=False, num_workers=os.cpu_count())\n",
    "}\n",
    "\n",
    "test_dl = cd.prepare_dataloader(dataset=test_ds, batch_size=64, shuffle=False, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare change detection net (avialable options: UNet and UNetPlusPlus)\n",
    "model = cd.UNet(\n",
    "    in_channels=3,\n",
    "    encoder_name='resnet34',\n",
    "    pretrained=True,\n",
    "    decoder_channels=(256, 128, 64, 32, 16),\n",
    "    encoder_fusion_type='concat',\n",
    "    decoder_attention_type='se',\n",
    "    classes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print change detection net summary\n",
    "cd.summary(model=model, input_size=((1, 3, 256, 256), (1, 3, 256, 256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare change detection learner\n",
    "loss = L.FocalLoss()\n",
    "optim = torch.optim.Adam(params=model.parameters(), lr=0.001, betas=(0.5, 0.99), weight_decay=0)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optim, step_size=10, gamma=0.1)\n",
    "\n",
    "learner = cd.prepare_learning(\n",
    "    model=model, \n",
    "    loss=loss, \n",
    "    optim=optim, \n",
    "    scheduler=scheduler, \n",
    "    num_epoch=25, \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train change detection net\n",
    "train_logs, valid_logs = learner.train(data_loader=train_dl, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save change detection net as onnx\n",
    "cd.export_onnx(model=model, input_size=((1, 3, 256, 256), (1, 3, 256, 256)), filename='change detection.onnx', \\\n",
    "    input_names=['base image', 'target image'], output_names=['change map'], opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test change detection net\n",
    "test_logs = learner.predict(data_loader=test_dl, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dechunk results (optional)\n",
    "chunker = cd.chunk_data(number_tiles=16)\n",
    "_ = chunker.dechunk(data_root='res/vis')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc11a0ee7a98b694b83c3c4a0db687354d2be2aaf7ade1a1aa091e5d9de8c33e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
